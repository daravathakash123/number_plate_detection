{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxW3Qg-ScurV"
   },
   "source": [
    "#### This notebook is used to train a character recongition from input image using MobileNets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XJmrQrB_curX",
    "outputId": "5a4bee5b-8c58-41bb-cd70-ff9ffa406ff9"
   },
   "outputs": [],
   "source": [
    "# ignore warning \n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8ApWHt8curj"
   },
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "-y1mnjyPcurk",
    "outputId": "de256a8f-5bb5-47c7-91c5-b29832539766",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_paths = glob.glob(\"dataset_characters/**/*.jpg\")\n",
    "\n",
    "cols=4\n",
    "rows=3\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.rcParams.update({\"font.size\":14})\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=rows,figure=fig)\n",
    "\n",
    "# create a random list of images will be displayed\n",
    "np.random.seed(45)\n",
    "rand = np.random.randint(0,len(dataset_paths),size=(cols*rows))\n",
    "\n",
    "# Plot image\n",
    "for i in range(cols*rows):\n",
    "    fig.add_subplot(grid[i])\n",
    "    image = load_img(dataset_paths[rand[i]])\n",
    "    label = dataset_paths[rand[i]].split(os.path.sep)[-2]\n",
    "    plt.title('\"{:s}\"'.format(label))\n",
    "    plt.axis(False)\n",
    "    plt.imshow(image)\n",
    "\n",
    "plt.savefig(\"Visualize_dataset.jpg\",dpi=300)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJzYBWt3bzAj"
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Yh443FGFRgFP",
    "outputId": "2fdc22f4-e393-4ae1-bb86-d5fb55ed1865"
   },
   "outputs": [],
   "source": [
    "# Arange input data and corresponding labels\n",
    "X=[]\n",
    "labels=[]\n",
    "\n",
    "for image_path in dataset_paths:\n",
    "  label = image_path.split(os.path.sep)[-2]\n",
    "  image=load_img(image_path,target_size=(80,80))\n",
    "  image=img_to_array(image)\n",
    "\n",
    "  X.append(image)\n",
    "  labels.append(label)\n",
    "\n",
    "X = np.array(X,dtype=\"float16\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"[INFO] Find {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n",
    "\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelEncoder()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "y = to_categorical(labels)\n",
    "\n",
    "# save label file so we can use in another script\n",
    "np.save('license_character_classes.npy', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOHM-oeWSsPd"
   },
   "outputs": [],
   "source": [
    "# split 10% of data as validation set\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DfUhlOTcurq"
   },
   "outputs": [],
   "source": [
    "# data augumentation\n",
    "image_gen = ImageDataGenerator(rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.1,\n",
    "                              fill_mode=\"nearest\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNMFc03Mb45i"
   },
   "source": [
    "## Initialize MobileNets architecture with pre-trained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaemgepFcur0"
   },
   "outputs": [],
   "source": [
    "# Create our model with pre-trained MobileNetV2 architecture from imagenet\n",
    "def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\", \n",
    "                            include_top=False,\n",
    "                            input_tensor=Input(shape=(80, 80, 3)))\n",
    "\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n",
    "    \n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    \n",
    "    if training:\n",
    "        # define trainable lalyer\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = True\n",
    "        # compile model\n",
    "        optimizer = Adam(lr=lr, decay = decay)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "-B5O6zG_cur5",
    "outputId": "83bfaffb-85bd-4219-da8e-ed68d7c656ad"
   },
   "outputs": [],
   "source": [
    "# initilaize initial hyperparameter\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 30\n",
    "\n",
    "model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JR0L3nWgb-gK"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4d4NQLwDcusA",
    "outputId": "29c5fad5-3f23-427c-f04c-01af2a140e40"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "my_checkpointer = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\n",
    "                ]\n",
    "\n",
    "result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), \n",
    "                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n",
    "                   validation_data=(testX, testY), \n",
    "                   validation_steps=len(testX) // BATCH_SIZE, \n",
    "                   epochs=EPOCHS, callbacks=my_checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "va-WvqTpcCJw"
   },
   "source": [
    "## Visualize training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "qUYOQrVzcusF",
    "outputId": "66bf8f56-e839-40bb-f1b7-3d7307c7fe26"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(14,5))\n",
    "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n",
    "fig.add_subplot(grid[0])\n",
    "plt.plot(result.history['accuracy'], label='training accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(grid[1])\n",
    "plt.plot(result.history['loss'], label='training loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"Training_result.jpg\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8JOq60Xw1UY"
   },
   "outputs": [],
   "source": [
    "# save model architectur as json file\n",
    "model_json = model.to_json()\n",
    "with open(\"MobileNets_character_recognition.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t92Je4kBbs0g"
   },
   "source": [
    "## The End!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train_license_character_recognition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
